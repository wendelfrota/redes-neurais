{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Redes Sociais: [GitHub](https://github.com/wendelfrota) | [Linkedin](www.linkedin.com/in/wendel-frota-11649b279)"
      ],
      "metadata": {
        "id": "WKfVnjcS96_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bilioteca do HuggingFace para Conjuntos de Dados:"
      ],
      "metadata": {
        "id": "wF6vsdMcW1aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "id": "cwBQNE69WHtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importação das Bibliotecas"
      ],
      "metadata": {
        "id": "hsPgJBUeXtqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "HIEV9Fe-WYkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaração dos Hiperparâmetros e Variáveis\n",
        "\n",
        "Explicarei cada uma delas mais à frente"
      ],
      "metadata": {
        "id": "sOTKO8nLXxCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab = 12000\n",
        "embedding_dim = 60\n",
        "max_length = 220\n",
        "optimizer = 'adam'\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = ['accuracy', 'mae']\n",
        "batch = 32\n",
        "epochs = 9"
      ],
      "metadata": {
        "id": "gWmA4nCVWZ9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando o Conjunto de Dados\n",
        "\n",
        "Nessa célula estamos:\n",
        "\n",
        "* Carregando o conjunto de dados do imdb, que possui:\n",
        "> Avaliações\\\n",
        "> Rótulos (1-Boa, 2-Ruim)\n",
        "* Separando o conjunto em:\n",
        "> Avaliações e Rótulos de TREINO\\\n",
        "> Avaliações e Rótulos de TESTE\n",
        "\n",
        "\\\n",
        "\n",
        "**Importante ressaltar que à todo momento iremos utilizar a biblioteca NumPy, pois:**\n",
        "* É mais veloz que as listas convencionais do Python\n",
        "* Realiza uma ampla variedade de operações matemáticas em matrizes\n",
        "* Fornece uma enorme biblioteca de funções matemáticas de alto nível"
      ],
      "metadata": {
        "id": "z1xC0yNaZorD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "dataset = load_dataset('imdb')\n",
        "train_reviews = np.array(dataset['train']['text'])\n",
        "train_labels = np.array(dataset['train']['label'])\n",
        "\n",
        "test_reviews = np.array(dataset['test']['text'])\n",
        "test_labels = np.array(dataset['test']['label'])"
      ],
      "metadata": {
        "id": "9cBNawSLWckT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando os Dados\n",
        "\n",
        "Nessa célula estamos:\n",
        "\n",
        "* Inicializando um objeto Tokenizer, que faz a transformação de texto em sequências de tokens, com:\n",
        "> * **num_words=vocab:** Um tamanho de vocabulário (variável definida no inicio do notebook)\n",
        "> * **oov_token=<OOV\\>:** Se uma palavra não estiver no vocabulário, ela será substituída pelo token <OOV> (Out Of Vocabulary), útil para palavras fora do vocabulário que aparecem durante a fase de teste ou inferência.\n",
        "\n",
        "* Ajustando o Tokenizer aos textos de treinamento para construir o índice de palavras, ou seja, estamos criando uma representação numérica correspondente\n",
        "\n",
        "* Convertendo as avaliações de treinamento e de teste em sequências de números inteiros\n",
        "\n",
        "* Preenchendo as sequências de treinamento e teste para terem o mesmo comprimento, com:\n",
        "> * **maxlen=max_length:** Comprimento máximo das sequências, truncando/removendo ou preenchendo sequências não adequadas (variável definida no inicio do notebook)\n",
        "> * **truncating='post':** Define que o truncamento deve ser feito no final da sequência\n",
        "> * **padding='post':** Define que o preenchimento deve ser feito no final da sequência\n",
        "\n",
        "Além de criar uma tupla para validação do modelo mais à frente"
      ],
      "metadata": {
        "id": "pxiCLt9Wf4L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "train_reviews = tokenizer.texts_to_sequences(train_reviews)\n",
        "test_reviews = tokenizer.texts_to_sequences(test_reviews)\n",
        "train_reviews = pad_sequences(train_reviews, maxlen=max_length, truncating='post', padding='post')\n",
        "test_reviews = pad_sequences(test_reviews, maxlen=max_length, truncating='post', padding='post')\n",
        "\n",
        "val_data = (test_reviews, test_labels)"
      ],
      "metadata": {
        "id": "xzdk4fdeWek7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando Modelo\n",
        "\n",
        "E, finalmente, estamos criando as redes neurais do nosso modelo:\n",
        "* Instanciando um modelo sequencial\n",
        "* Adicionando camadas de embedding (variáveis definidas no inicio do notebook):\n",
        "> **Embedding:** Resumidamente, a camada aprende representações densas e contínuas das palavras, capturando semelhanças semânticas e contextuais\n",
        "> * **input_dim=vocab:** Tamanho do vocabulário\n",
        "> * **output_dim=embedding_dim:** Tamanho da dimensão do vetor de embedding, ou seja, define qual o tamanho do vetor que representará cada palavra.\n",
        "> * **input_length=max_length:** Comprimento máximo da sequência de input.\n",
        "* Adicionando camadas de LSTM (Long Short-Term Memory):\n",
        "> **LSTM:** É projetado para lidar com informações de longo prazo\n",
        "* Adicionando cama dense:\n",
        "> **Dense:** É uma camada totalmente conectada à camada anterior e produz uma única saída neste caso (classificação binária)\n",
        "> * **activation='sigmoid':** Função de ativação para converter a saída da rede em uma probabilidade"
      ],
      "metadata": {
        "id": "Q8i6nDsRqfMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "# Model - Layers\n",
        "model.add(Embedding(input_dim=vocab, output_dim=embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(60))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "dX_JS3eiWfgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando Modelo\n",
        "\n",
        "Agora, na reta final do modelo:\n",
        "* Configuramos o modelo (variáveis definidas no inicio do notebook):\n",
        "> * **optimizer=optimizer:**  Algoritmo para ajustar os pesos da rede neural durante o treinamento e minimizar a função de perda\\\n",
        "Estamos usando o Adam (Adaptive Moment Estimation)\n",
        "> * **loss=loss:** Função de perda que queremos otimizar\\\n",
        "Estamos usando o binary_crossentropy para classificação binária\n",
        "> * **metrics=metrics:** Métricas para avaliar o desempenho do modelo durante o treinamento\\\n",
        "Estamos usando o MAE (Mean Absolute Error) e accuracy\n",
        "* Treinamos o modelo (variáveis definidas no inicio do notebook):\n",
        "> * **batch_size=batch:** O treinamento geralmente é feito em lotes para que o modelo não precise processar todo o conjunto de dados de uma só vez\n",
        "> * **epochs=epochs:** Número de vezes que o modelo passará por todo o conjunto de dados durante o treinamento\n",
        "> * **validation_data=val_data:** São usados para avaliar o desempenho do modelo, sendo útil para detectar problemas de sobreajuste (overfitting)\\\n",
        "Os resultados da validação não são usados para ajustar os pesos do modelo\n",
        "* Verificamos as informações do modelo já treinado\n",
        "* Salvamos"
      ],
      "metadata": {
        "id": "Z8RA0TGWCdqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model - Fit\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "result = model.fit(train_reviews, train_labels, batch_size=batch, epochs=epochs, validation_data=val_data)\n",
        "\n",
        "\n",
        "# Model - Info & Save\n",
        "model.summary()\n",
        "model.save('./model_trained_v1.keras')"
      ],
      "metadata": {
        "id": "E9Kj895pWlfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvando Histórico de Treinamento"
      ],
      "metadata": {
        "id": "TwdhAcUXDJwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log\n",
        "with open('history_log.txt', 'w') as f:\n",
        "    for key, value in result.history.items():\n",
        "        f.write(f\"{key}: {value}\\n\")"
      ],
      "metadata": {
        "id": "v0VNqWSOWnUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imprimindo Gráficos de Treinamento"
      ],
      "metadata": {
        "id": "GB56e0znDQtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsPx3FboUThH"
      },
      "outputs": [],
      "source": [
        "# Matplotlib\n",
        "plt.plot(result.history['loss'], label='Erro treino')\n",
        "plt.plot(result.history['val_loss'], label='Erro teste')\n",
        "plt.title('Histórico de Treinamento - Função de custo')\n",
        "plt.ylabel('Função de custo')\n",
        "plt.xlabel('Épocas de treinamento')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(result.history['accuracy'], label='Acurácia treino')\n",
        "plt.plot(result.history['val_accuracy'], label='Acurácia teste')\n",
        "plt.title('Histórico de Treinamento - Acurácia')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.xlabel('Épocas de treinamento')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quer aprender mais um pouquinho das tecnologias utilizadas aqui? Confira:\n",
        "\n",
        "### NumPy:\n",
        "* Site oficial: [numpy.org](https://numpy.org)\n",
        "* Qual a funcionalidade do NumPy? + Características [ [Clique aqui](https://cursos.alura.com.br/forum/topico-qual-a-funcionalidade-do-numpy-128044#:~:text=NumPy%20tem%20como%20objetivo%20fornecer,as%20listas%20tradicionais%20do%20Python.) ]\n",
        "* Por que o NumPy é mais rápido em Python? [ [Clique aqui](https://acervolima.com/por-que-o-numpy-e-mais-rapido-em-python/) ]\n",
        "\n",
        "\n",
        "### Keras\n",
        "* Site oficial: [keras.io](https://keras.io)\n",
        "* O que é Keras e para que serve? [ [Clique aqui](https://didatica.tech/o-que-e-keras-para-que-serve/) ]\n",
        "* Keras: The high-level API for TensorFlow [ [Clique aqui](https://www.tensorflow.org/guide/keras) ]\n",
        "\n",
        "### Matplotlib\n",
        "* Site oficial: [matplotlib.org](https://matplotlib.org)\n",
        "* Matplotlib uma biblioteca Python para gerar gráficos interessantes [ [Clique aqui](https://www.alura.com.br/artigos/criando-graficos-no-python-com-a-matplotlib) ]\n",
        "\n",
        "### HuggingFace\n",
        "* Site oficial: [huggingface.co](https://huggingface.co)"
      ],
      "metadata": {
        "id": "m63Q7bhIfnyT"
      }
    }
  ]
}